{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A1: Custom model on CIFAR-10\n",
    "\n",
    "For A1, we're asked to implement a custom model on CIFAR-10. I'll be using a CNN model and saving it to the ONNX format for portability.\n",
    "\n",
    "For target accuracy, we're asked to get within \"3-5% of industry standard\" accuracy. Based on this, we'll target 90% accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "LEARN_RATE = 0.001\n",
    "NUM_EPOCHS = 10\n",
    "CNN_ARCHITECTURE = {\n",
    "    \"conv_layers\": [\n",
    "        {\"in_channels\": 3, \"out_channels\": 32, \"kernel_size\": 3, \"padding\": 1},\n",
    "        {\"in_channels\": 32, \"out_channels\": 64, \"kernel_size\": 3, \"padding\": 1},\n",
    "    ],\n",
    "    \"fc_layers\": [\n",
    "        {\"in_features\": 64 * 8 * 8, \"out_features\": 512},\n",
    "        {\"in_features\": 512, \"out_features\": 10},\n",
    "    ],\n",
    "    \"pool_size\": (2, 2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard setup\n",
    "writer = SummaryWriter(\"runs/cifar10_experiment_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>learn_rate</th>\n",
       "      <th>conv_layers</th>\n",
       "      <th>fc_layers</th>\n",
       "      <th>pool_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7245</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[{\"in_channels\": 3, \"out_channels\": 32, \"kerne...</td>\n",
       "      <td>[{\"in_features\": 4096, \"out_features\": 512}, {...</td>\n",
       "      <td>(2, 2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_accuracy  num_epochs  learn_rate  \\\n",
       "0         0.7245          10       0.001   \n",
       "\n",
       "                                         conv_layers  \\\n",
       "0  [{\"in_channels\": 3, \"out_channels\": 32, \"kerne...   \n",
       "\n",
       "                                           fc_layers pool_size  \n",
       "0  [{\"in_features\": 4096, \"out_features\": 512}, {...    (2, 2)  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a dataframe for results\n",
    "# df = pd.DataFrame(\n",
    "#     columns=[\n",
    "#         \"test_accuracy\",\n",
    "#         \"num_epochs\",\n",
    "#         \"learn_rate\",\n",
    "#         \"conv_layers\",\n",
    "#         \"fc_layers\",\n",
    "#         \"pool_size\",\n",
    "#     ]\n",
    "# )\n",
    "df = pd.read_csv('a1_results.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure we're using GPU\n",
    "device = torch.device(\n",
    "    \"mps\"  # for macOS\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use this to normalize the data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "           )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "           )"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting train dataset into train and validation sets\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Model Design\n",
    "\n",
    "We will create a simple CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, architecture):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(**architecture['conv_layers'][0])\n",
    "        self.conv2 = nn.Conv2d(**architecture['conv_layers'][1])\n",
    "        self.pool = nn.MaxPool2d(*architecture['pool_size'])\n",
    "        self.fc1 = nn.Linear(**architecture['fc_layers'][0])\n",
    "        self.fc2 = nn.Linear(**architecture['fc_layers'][1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleCNN(CNN_ARCHITECTURE).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARN_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:11<00:00, 19.10s/it]\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "def train_model(num_epochs):\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Log loss to TensorBoard\n",
    "            writer.add_scalar(\"Loss/train\", loss.item(), epoch * len(train_loader) + i)\n",
    "\n",
    "\n",
    "train_model(NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluation and Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the validation images: 72.45%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model():\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "results = evaluate_model()\n",
    "print(f\"Accuracy of the model on the validation images: {results * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/ggny_vpn0nv4f9ys1m85vyv80000gn/T/ipykernel_54619/2186680173.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>learn_rate</th>\n",
       "      <th>conv_layers</th>\n",
       "      <th>fc_layers</th>\n",
       "      <th>pool_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7245</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[{\"in_channels\": 3, \"out_channels\": 32, \"kerne...</td>\n",
       "      <td>[{\"in_features\": 4096, \"out_features\": 512}, {...</td>\n",
       "      <td>(2, 2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_accuracy num_epochs  learn_rate  \\\n",
       "0         0.7245         10       0.001   \n",
       "\n",
       "                                         conv_layers  \\\n",
       "0  [{\"in_channels\": 3, \"out_channels\": 32, \"kerne...   \n",
       "\n",
       "                                           fc_layers pool_size  \n",
       "0  [{\"in_features\": 4096, \"out_features\": 512}, {...    (2, 2)  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write results to the dataframe\n",
    "new_row = pd.DataFrame(\n",
    "    [\n",
    "        [\n",
    "            NUM_EPOCHS,\n",
    "            LEARN_RATE,\n",
    "            results,\n",
    "            json.dumps(CNN_ARCHITECTURE[\"conv_layers\"]),\n",
    "            json.dumps(CNN_ARCHITECTURE[\"fc_layers\"]),\n",
    "            CNN_ARCHITECTURE[\"pool_size\"],\n",
    "        ],\n",
    "    ],\n",
    "    columns=[\n",
    "        \"num_epochs\",\n",
    "        \"learn_rate\",\n",
    "        \"test_accuracy\",\n",
    "        \"conv_layers\",\n",
    "        \"fc_layers\",\n",
    "        \"pool_size\",\n",
    "    ],\n",
    ")\n",
    "df = pd.concat([df, new_row], ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "df.to_csv(\"a1_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the model in ONNX format\n",
    "# dummy_input = torch.randn(1, 3, 32, 32, device=device) # Needed for ONNX tracing operation\n",
    "# torch.onnx.export(model, dummy_input, \"a1_model_best.onnx\", export_params=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
